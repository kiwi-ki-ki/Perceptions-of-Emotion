# Perceptions-of-Emotion

Replicating a 2011 study by Lott et al., this analysis aimed to determine individuals' recognition of facial expressions and body language as emotions. 

This study'sd particiapnts were required to completed two trials, one for facial expressions and one for body language. For Trial 1, particiapnts were first shown a facial vignette then asked to guess which emotion the face was making from three choices; anger, hppiness, or sadness. Each of the vignettes were shown for 1 second and were displayed in greyscale to reduce biases. For Trial 2, 13-point black and white dot matricies were used, where each dot represented a major joint or part of the body. The animation of the matrices was one second long and during it one movement was perfromed. The participants were given the same three emotion choices from before; anger, happiness, and sadness. The participants were evaluated by accuracy and response time. 

Example of the facial vignettes:

https://github.com/kiwi-ki-ki/Perceptions-of-Emotion/assets/142944301/eb1d324d-f6d7-4a05-8d97-513faeb8e159

Example of the body dot matrices:

https://github.com/kiwi-ki-ki/Perceptions-of-Emotion/assets/142944301/edf71d51-1729-4729-8898-ec8fc1ea35f4

The experiment was built on PsychoPY utilizing Python and hosted on Pavlovia for data collection. The data preprocessing and analysis was comepleted in R Studio with R. 

The attached files inlcude the raw data extracted from Pavlovia, the data analysis in R, and the final paper summarizing the replicated study. 

Contributors: Kiera Wingo & Dr. Matthew Robison from the department of Psychology at The Univeristy of Texas at Arlington. 
